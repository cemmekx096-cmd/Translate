# ========== ENHANCED BATCH PROCESSING FOR GOOGLE & BING ==========

import time
from collections import defaultdict

class BatchAwareMultiEngineTranslator:
    """Enhanced multi-engine translator with batch processing for Google & Bing"""
    
    def __init__(self, logger):
        self.logger = logger
        
        # Engine cascade configuration
        self.engines = [
            GoogleEngine(logger),
            BingEngine(logger), 
            LingvaEngine(logger),
            ShellEngine(logger)
        ]
        
        # Batch processing configuration
        self.BATCH_SIZE = 5  # Process 5 files per batch for Google/Bing
        self.BATCH_DELAY = 30  # 30 seconds delay between batches
        
        # Enhanced blocking system
        self.blocked_engines = set()
        self.failure_counts = defaultdict(int)
        self.success_counts = defaultdict(int)
        
        # Batch tracking
        self.current_file_count = 0
        self.batch_number = 1
        self.files_in_current_batch = 0
        
        # Statistics
        self.stats = {
            'google': 0,
            'bing': 0, 
            'lingva': 0,
            'shell': 0,
            'failed': 0,
            'blocked_saves': 0,
            'batch_delays': 0
        }
    
    def _should_use_batch_delay(self, engine_name):
        """Check if engine needs batch delay management"""
        return engine_name.lower() in ['google', 'bing']
    
    def _handle_batch_transition(self):
        """Handle transition between file batches for Google/Bing"""
        self.files_in_current_batch += 1
        
        # Check if we've completed a batch
        if self.files_in_current_batch >= self.BATCH_SIZE:
            # Check if Google or Bing are still active (not blocked)
            active_batch_engines = [e.name for e in self.engines 
                                  if e.name not in self.blocked_engines 
                                  and self._should_use_batch_delay(e.name)]
            
            if active_batch_engines:
                log_message(f"ğŸ“¦ Batch {self.batch_number} completed ({self.BATCH_SIZE} files)")
                log_message(f"â³ Cooling down for {active_batch_engines} engines...")
                log_message(f"ğŸ’¤ Waiting {self.BATCH_DELAY}s before next batch...")
                
                time.sleep(self.BATCH_DELAY)
                self.stats['batch_delays'] += 1
                
                # Reset batch counters
                self.batch_number += 1
                self.files_in_current_batch = 0
                
                log_message(f"ğŸ”„ Starting batch {self.batch_number}")
    
    def translate_single(self, text, file_context=None):
        """Enhanced translate with batch awareness"""
        if not text or not text.strip():
            return text
        
        active_engines = self._get_active_engines()
        
        if not active_engines:
            log_message("âŒ All engines blocked! Resetting...")
            self.blocked_engines.clear()
            self.failure_counts.clear()
            active_engines = self.engines
        
        # Try each active engine
        for engine in active_engines:
            try:
                # Add extra delay for batch engines if needed
                if self._should_use_batch_delay(engine.name):
                    # Add small extra delay for Google/Bing within batch
                    time.sleep(0.2)
                
                translated = engine.translate(text)
                
                # Success - update stats
                self.success_counts[engine.name] += 1
                self.failure_counts[engine.name] = 0
                
                engine_key = engine.name.lower()
                self.stats[engine_key] += 1
                
                return translated
                
            except RateLimitError:
                log_message(f"âš ï¸ {engine.name} rate limited")
                self.failure_counts[engine.name] += 1
                
                # More aggressive blocking for batch engines
                if self._should_use_batch_delay(engine.name):
                    if self.failure_counts[engine.name] >= 2:  # Block after 2 failures
                        self.blocked_engines.add(engine.name)
                        log_message(f"ğŸš« {engine.name} blocked (batch engine rate limit)")
                else:
                    if self._should_block_engine(engine.name):
                        self.blocked_engines.add(engine.name)
                        log_message(f"ğŸš« {engine.name} blocked")
                
                continue
                
            except TranslationError as e:
                self.failure_counts[engine.name] += 1
                
                if self._should_block_engine(engine.name):
                    self.blocked_engines.add(engine.name)
                    log_message(f"ğŸš« {engine.name} blocked: {e}")
                
                continue
                
            except Exception as e:
                log_message(f"âŒ {engine.name} unexpected error: {e}")
                continue
        
        # All engines failed
        self.stats['failed'] += 1
        return text
    
    def _get_active_engines(self):
        """Get list of non-blocked engines"""
        return [e for e in self.engines if e.name not in self.blocked_engines]
    
    def _should_block_engine(self, engine_name):
        """Enhanced blocking logic with different thresholds for batch engines"""
        failures = self.failure_counts[engine_name]
        successes = self.success_counts[engine_name]
        total = failures + successes
        
        # More lenient blocking for Google/Bing
        if self._should_use_batch_delay(engine_name):
            # Block after 5 consecutive failures, or success rate < 10% after 10 attempts
            if failures >= 5 and successes == 0:
                return True
            elif total >= 10 and successes / total < 0.1:
                return True
        else:
            # Original logic for Lingva/Shell
            if failures >= 3 and successes == 0:
                return True
            elif total >= 5 and successes / total < 0.2:
                return True
        
        return False
    
    def print_stats(self):
        """Enhanced statistics with batch information"""
        total_attempts = sum(v for k, v in self.stats.items() 
                           if k not in ['blocked_saves', 'batch_delays'])
        
        if total_attempts == 0:
            return
        
        log_message("ğŸ“Š Enhanced Batch-Aware Statistics:")
        log_message(f"ğŸ“¦ Batch Configuration: {self.BATCH_SIZE} files/batch, {self.BATCH_DELAY}s delay")
        log_message(f"â¸ï¸ Batch delays executed: {self.stats['batch_delays']}")
        log_message(f"ğŸ“ Current batch: {self.batch_number}, Files in batch: {self.files_in_current_batch}")
        
        # Engine usage with batch info
        for engine in ['google', 'bing', 'lingva', 'shell']:
            count = self.stats[engine]
            if count > 0:
                percentage = (count / total_attempts) * 100
                batch_status = " (BATCH ENGINE)" if engine in ['google', 'bing'] else ""
                log_message(f"  {engine.title()}: {count} texts ({percentage:.1f}%){batch_status}")
        
        # Rest of statistics...
        if self.stats['failed'] > 0:
            failed_pct = (self.stats['failed'] / total_attempts) * 100
            log_message(f"  Failed: {self.stats['failed']} texts ({failed_pct:.1f}%)")
        
        if self.blocked_engines:
            log_message(f"  Currently blocked: {', '.join(self.blocked_engines)}")

# ========== ENHANCED FILE PROCESSING WITH BATCH AWARENESS ==========

def process_files_with_batching(file_list, translator):
    """Enhanced file processing with batch management for Google/Bing"""
    log_message(f"ğŸš€ Starting batch-aware processing for {len(file_list)} files...")
    log_message(f"ğŸ“¦ Batch config: {translator.BATCH_SIZE} files per batch, {translator.BATCH_DELAY}s delay")
    
    results = []
    
    for i, filename in enumerate(file_list, 1):
        log_message(f"ğŸ“„ Processing file {i}/{len(file_list)}: {filename}")
        
        filepath = REPO_ROOT / "tl" / filename
        logger = TranslationLogger()
        renpy_translator = RenPyTranslatorCore(filepath, logger)
        
        # Create translation function with file context
        def translate_with_context(text):
            return translator.translate_single(text, file_context=filename)
        
        result = renpy_translator.process_file(translate_with_context)
        
        if result:
            # Save translated file
            output_filename = REPO_ROOT / "output_tl" / "id" / f"{result['filename']}_translated.rpy"
            
            with open(output_filename, 'w', encoding='utf-8') as f:
                f.write(result['content'])
                
            log_message(f"ğŸ’¾ Saved: {output_filename}")
            
            # Save session log
            log_file = logger.save_session_log()
            result['log_file'] = log_file
            results.append(result)
        
        # Handle batch transition AFTER each file
        translator._handle_batch_transition()
        
        log_message("-" * 50)
    
    log_message(f"ğŸ‰ Batch processing completed! {len(results)}/{len(file_list)} files processed successfully.")
    return results

# ========== MODIFIED MAIN FUNCTION ==========

def main():
    """Modified main execution with batch processing"""
    log_message("ğŸš€ Starting BATCH-AWARE multi-engine translation pipeline...")
    log_message("ğŸ“¦ Google & Bing: Process 5 files â†’ 30s delay â†’ Next batch")
    log_message("âš¡ Lingva & Shell: Continuous processing")
    
    # Read assigned files
    my_files = read_my_tasks()
    log_message(f"ğŸ“‹ Found {len(my_files)} assigned files")
    
    if not my_files:
        log_message(f"âšª No files assigned to pattern {PATTERN}")
        return
    
    # Check existing files
    existing_files = []
    for filename in my_files:
        filepath = REPO_ROOT / "tl" / filename
        if filepath.exists():
            existing_files.append(filename)
        else:
            log_message(f"âš ï¸ File not found: {filepath}")
    
    if not existing_files:
        log_message("âŒ No valid files found!")
        return
    
    log_message(f"âœ… Processing {len(existing_files)} valid files...")
    
    # Calculate expected batches
    expected_batches = (len(existing_files) + 4) // 5  # Ceiling division
    total_batch_time = (expected_batches - 1) * 30  # -1 because no delay after last batch
    log_message(f"ğŸ“¦ Expected {expected_batches} batches, ~{total_batch_time}s batch delays")
    
    # Initialize enhanced batch-aware translator
    session_logger = TranslationLogger()
    translator = BatchAwareMultiEngineTranslator(session_logger)
    
    try:
        # Process files with batch management
        results = process_files_with_batching(existing_files, translator)
        
        # Print comprehensive statistics
        translator.print_stats()
        
        if results:
            log_message(f"ğŸ‰ {SCRIPT_NAME} completed successfully!")
            log_message(f"   Processed: {len(results)} files in {translator.batch_number} batches")
        else:
            log_message("âŒ No files were processed successfully")
            
    except Exception as e:
        log_message(f"âŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()

# Usage example:
if __name__ == "__main__":
    main()